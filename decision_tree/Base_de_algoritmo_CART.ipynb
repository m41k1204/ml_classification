{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df5d276",
   "metadata": {},
   "source": [
    "# Árboles de decisión y el algoritmo CART\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "Los **árboles de decisión** constituyen uno de los métodos más interpretables y ampliamente utilizados en el aprendizaje automático supervisado.  \n",
    "Su estructura jerárquica permite dividir progresivamente el espacio de atributos en regiones homogéneas respecto a la variable de salida, generando reglas de decisión de fácil comprensión.  \n",
    "\n",
    "Cada división (o *split*) en el árbol se selecciona con el objetivo de reducir al máximo la heterogeneidad de las clases en los nodos hijos.  \n",
    "Para lograrlo, se emplean métricas de **impureza**, como la **entropía** o el **índice de Gini**.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f96b85",
   "metadata": {},
   "source": [
    "## 2. Medidas de impureza: Entropía vs. Gini\n",
    "\n",
    "- **Entropía** (usada en ID3/C4.5):\n",
    "  $$\n",
    "  H(t) = -\\sum_{j=1}^K p(j\\mid t)\\,\\log_2 p(j\\mid t)\n",
    "  $$\n",
    "\n",
    "  mide el desorden en el nodo. Valores altos indican una distribución equilibrada de clases.\n",
    "\n",
    "- **Índice de Gini** (usado en CART):  \n",
    "  $$\n",
    "  H(t) = -\\sum_{j=1}^K p(j\\mid t)\\,\\log_2 p(j\\mid t)\n",
    "  $$\n",
    "\n",
    "  mide la probabilidad de clasificación errónea al asignar etiquetas al azar según la distribución de clases.  \n",
    "\n",
    "Ambas métricas son coherentes y producen resultados similares en la práctica.  \n",
    "Sin embargo, el índice de Gini es **computacionalmente más eficiente**, al no requerir el cálculo de logaritmos, y tiende a generar divisiones algo más equilibradas en cuanto al tamaño de los nodos.  \n",
    "Por estas razones, **CART adopta Gini como medida por defecto**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f3336",
   "metadata": {},
   "source": [
    "## 3. De binario a multiclase\n",
    "\n",
    "En sus orígenes, los árboles de decisión se aplicaron principalmente a problemas de **clasificación binaria**.  \n",
    "No obstante, la definición del índice de Gini es lo suficientemente general para extenderse de manera inmediata al caso de **múltiples clases**:\n",
    "\n",
    "$$\n",
    "\\text{Gini}(t) = 1 - \\sum_{j=1}^K p(j \\mid t)^2, \\quad K \\geq 2\n",
    "$$\n",
    "\n",
    "\n",
    "De esta forma, la estructura binaria del árbol (dos nodos hijos por división) se mantiene, pero los nodos pueden contener observaciones de varias clases simultáneamente.  \n",
    "El criterio de división sigue siendo válido en cualquier escenario: minimizar la impureza ponderada de los nodos hijos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e79cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff3f5028",
   "metadata": {},
   "source": [
    "\n",
    "## Criterio de división\n",
    "\n",
    "Cuando un nodo se divide en dos hijos \\(t_L\\) y \\(t_R\\), CART calcula la **impureza ponderada** de los hijos.  \n",
    "El objetivo es **minimizar esta cantidad**, de manera que los nodos hijos sean lo más puros posible.\n",
    "\n",
    "$$\n",
    "\\text{Impureza ponderada}(s, t) =\n",
    "\\frac{n_L}{n}\\,\\text{Gini}(t_L) +\n",
    "\\frac{n_R}{n}\\,\\text{Gini}(t_R)\n",
    "$$\n",
    "\n",
    "- \\(s\\): split propuesto.  \n",
    "- \\(n_L, n_R\\): número de observaciones en los nodos izquierdo y derecho.  \n",
    "- \\(n = n_L + n_R\\).  \n",
    "CART selecciona el split \\(s^*\\) que **minimiza** esta impureza ponderada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfb43f",
   "metadata": {},
   "source": [
    "## Búsqueda de umbral en variables continuas\n",
    "\n",
    "Para variables numéricas, CART **ordena los valores de la característica** y evalúa cortes posibles entre observaciones consecutivas distintas.  \n",
    "Cada corte se coloca en el **punto medio** entre dos valores distintos.\n",
    "\n",
    "$$\n",
    "c = \\frac{x_{(i)} + x_{(i+1)}}{2}, \n",
    "\\quad \\text{con } n-1 \\text{ posibles cortes entre valores consecutivos}\n",
    "$$\n",
    "\n",
    "- Si los valores son iguales, no se prueba un corte (no aporta nada).  \n",
    "- Si los valores difieren, el corte se evalúa justo en el medio.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355a514",
   "metadata": {},
   "source": [
    "## Resumen del procedimiento CART\n",
    "\n",
    "1. Elegir un nodo actual con datos.  \n",
    "2. Para cada característica:\n",
    "   - Ordenar los valores.  \n",
    "   - Evaluar todos los cortes posibles entre valores consecutivos distintos.  \n",
    "   - Calcular la impureza ponderada.  \n",
    "3. Seleccionar el split con **menor impureza**.  \n",
    "4. Repetir el proceso recursivamente en cada nodo hijo.  \n",
    "5. Parar cuando se alcance un nodo puro o un criterio de detención (profundidad máxima, número mínimo de muestras, etc.).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
